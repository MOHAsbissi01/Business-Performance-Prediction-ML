<!DOCTYPE html>
<html lang="fr">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Analyse de R√©gression Approfondie | Global Superstore Sales</title>
  <link rel="stylesheet" href="../../style.css" />
  <link rel="stylesheet" href="regression.css" />
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&display=swap"
    rel="stylesheet">
  <style>
    body {
      background: #0a0e27;
      color: #e4e8f0;
      font-family: 'Inter', sans-serif;
      line-height: 1.8;
    }

    .container {
      max-width: 1100px;
      margin: 0 auto;
      padding: 0 2rem;
    }

    .hero-section {
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      padding: 80px 0;
      text-align: center;
      color: white;
      margin-bottom: 60px;
    }

    .hero-section h1 {
      font-size: 3.5rem;
      margin-bottom: 1rem;
      font-weight: 800;
    }

    .hero-section .lead {
      font-size: 1.3rem;
      opacity: 0.95;
      max-width: 800px;
      margin: 0 auto;
    }

    .hero-stats {
      display: flex;
      justify-content: center;
      gap: 40px;
      margin-top: 40px;
      flex-wrap: wrap;
    }

    .hero-stats .stat {
      text-align: center;
    }

    .hero-stats .stat h3 {
      font-size: 2.5rem;
      margin: 0;
      font-weight: 700;
    }

    .hero-stats .stat p {
      margin: 5px 0 0;
      opacity: 0.9;
    }

    .section {
      background: rgba(20, 27, 61, 0.6);
      border-radius: 20px;
      padding: 50px;
      margin-bottom: 40px;
      border: 1px solid rgba(139, 92, 246, 0.2);
    }

    .section h2 {
      color: #a78bfa;
      font-size: 2.2rem;
      margin-bottom: 1.5rem;
      border-bottom: 3px solid #667eea;
      padding-bottom: 15px;
    }

    .section h3 {
      color: #60a5fa;
      font-size: 1.8rem;
      margin-top: 2.5rem;
      margin-bottom: 1.2rem;
    }

    .section h4 {
      color: #c4b5fd;
      font-size: 1.4rem;
      margin-top: 2rem;
      margin-bottom: 1rem;
    }

    .methodology-box {
      background: linear-gradient(135deg, rgba(102, 126, 234, 0.15), rgba(118, 75, 162, 0.15));
      border-left: 5px solid #667eea;
      padding: 30px;
      border-radius: 12px;
      margin: 30px 0;
    }

    .formula {
      background: rgba(0, 0, 0, 0.3);
      padding: 20px 30px;
      border-radius: 12px;
      font-family: 'Courier New', monospace;
      font-size: 1.1rem;
      margin: 20px 0;
      border: 2px solid #667eea;
      text-align: center;
      color: #f0abfc;
    }

    .insight-box {
      background: linear-gradient(135deg, rgba(96, 165, 250, 0.12), rgba(139, 92, 246, 0.12));
      border-left: 5px solid #60a5fa;
      padding: 25px;
      border-radius: 12px;
      margin: 25px 0;
      font-size: 1.05rem;
    }

    .insight-box strong {
      color: #60a5fa;
    }

    .warning-box {
      background: linear-gradient(135deg, rgba(251, 146, 60, 0.15), rgba(239, 68, 68, 0.15));
      border-left: 5px solid #fb923c;
      padding: 25px;
      border-radius: 12px;
      margin: 25px 0;
    }

    .warning-box strong {
      color: #fb923c;
    }

    .success-box {
      background: linear-gradient(135deg, rgba(52, 211, 153, 0.15), rgba(16, 185, 129, 0.15));
      border-left: 5px solid #34d399;
      padding: 25px;
      border-radius: 12px;
      margin: 25px 0;
    }

    .success-box strong {
      color: #34d399;
    }

    .results-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
      gap: 20px;
      margin: 30px 0;
    }

    .metric-card {
      background: rgba(139, 92, 246, 0.1);
      border: 2px solid #667eea;
      padding: 25px;
      border-radius: 16px;
      text-align: center;
      transition: transform 0.3s, box-shadow 0.3s;
    }

    .metric-card:hover {
      transform: translateY(-5px);
      box-shadow: 0 10px 30px rgba(102, 126, 234, 0.4);
    }

    .metric-card h4 {
      color: #c4b5fd;
      font-size: 0.95rem;
      margin: 0 0 10px;
      text-transform: uppercase;
    }

    .metric-card .value {
      font-size: 2.5rem;
      font-weight: 800;
      color: #a78bfa;
    }

    .metric-card.best {
      border-color: #34d399;
      background: rgba(52, 211, 153, 0.15);
    }

    .metric-card.best .value {
      color: #34d399;
    }

    .image-wrapper {
      margin: 40px 0;
      border-radius: 16px;
      overflow: hidden;
      box-shadow: 0 20px 60px rgba(0, 0, 0, 0.5);
    }

    .image-wrapper img {
      width: 100%;
      display: block;
    }

    .image-caption {
      text-align: center;
      margin-top: 15px;
      font-style: italic;
      color: #9ca3af;
      font-size: 0.95rem;
    }

    .image-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
      gap: 30px;
      margin: 40px 0;
    }

    .step-number {
      display: inline-block;
      background: #667eea;
      color: white;
      width: 40px;
      height: 40px;
      border-radius: 50%;
      text-align: center;
      line-height: 40px;
      font-weight: 700;
      margin-right: 15px;
      font-size: 1.2rem;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      margin: 30px 0;
      background: rgba(20, 27, 61, 0.4);
      border-radius: 12px;
      overflow: hidden;
    }

    thead {
      background: rgba(102, 126, 234, 0.3);
    }

    th,
    td {
      padding: 15px;
      text-align: left;
      border-bottom: 1px solid rgba(139, 92, 246, 0.2);
    }

    th {
      color: #a78bfa;
      font-weight: 600;
    }

    tr:hover {
      background: rgba(139, 92, 246, 0.1);
    }

    .process-flow {
      background: rgba(20, 27, 61, 0.6);
      border-radius: 16px;
      padding: 30px;
      margin: 30px 0;
    }

    .process-step {
      padding: 20px 0;
      border-left: 3px solid #667eea;
      padding-left: 30px;
      margin-left: 20px;
      position: relative;
    }

    .process-step::before {
      content: '';
      position: absolute;
      left: -8px;
      top: 25px;
      width: 13px;
      height: 13px;
      border-radius: 50%;
      background: #667eea;
      border: 3px solid #0a0e27;
    }

    code {
      background: rgba(139, 92, 246, 0.2);
      padding: 3px 8px;
      border-radius: 6px;
      color: #f0abfc;
      font-family: 'Courier New', monospace;
      font-size: 0.95em;
    }

    .nav-top {
      background: rgba(10, 14, 39, 0.95);
      padding: 20px 0;
      position: sticky;
      top: 0;
      z-index: 100;
      border-bottom: 1px solid rgba(139, 92, 246, 0.3);
    }

    .nav-top .container {
      display: flex;
      justify-content: space-between;
      align-items: center;
    }

    .nav-top a {
      color: #a78bfa;
      text-decoration: none;
      transition: color 0.3s;
    }

    .nav-top a:hover {
      color: #c4b5fd;
    }
  </style>
</head>

<body>

  <!-- Navigation -->
  <nav class="nav-top">
    <div class="container">
      <a href="../index.html">‚Üê Apprentissage Supervis√©</a>
      <a href="../../index.html">üè† Accueil</a>
      <a href="../classification/index.html">Classification ‚Üí</a>
    </div>
  </nav>

  <!-- Hero Section -->
  <header class="hero-section">
    <div class="container">
      <h1>üìä Analyse de R√©gression Approfondie</h1>
      <p class="lead">
        Pr√©diction des ventes avec mod√®les lin√©aires, polynomiaux et r√©gularisation<br>
        <strong>Une approche m√©thodologique compl√®te du Machine Learning supervis√©</strong>
      </p>
      <div class="hero-stats">
        <div class="stat">
          <h3>51 235</h3>
          <p>Commandes analys√©es</p>
        </div>
        <div class="stat">
          <h3>16</h3>
          <p>Features s√©lectionn√©es</p>
        </div>
        <div class="stat">
          <h3>0.784</h3>
          <p>R¬≤ final (Polynomial)</p>
        </div>
        <div class="stat">
          <h3>$110.3</h3>
          <p>MAE optimal</p>
        </div>
      </div>
    </div>
  </header>

  <div class="container">

    <!-- Introduction & Context -->
    <section class="section">
      <h2>üéØ Contexte et Objectif du Projet</h2>

      <p style="font-size: 1.15rem;">
        La r√©gression est au c≈ìur de l'apprentissage supervis√© pour la pr√©diction de valeurs continues.
        Dans le contexte du <strong>Global Superstore</strong>, notre objectif est de construire un mod√®le
        capable de <strong>pr√©dire avec pr√©cision le montant des ventes (Sales)</strong> d'une commande en
        fonction de ses caract√©ristiques.
      </p>

      <div class="methodology-box">
        <h4 style="color: #667eea; margin-top: 0;">üî¨ M√©thodologie Scientifique</h4>
        <p>Notre approche suit une d√©marche rigoureuse en 5 √©tapes :</p>

        <div class="process-flow">
          <div class="process-step">
            <strong style="color: #a78bfa;">√âtape 1 : Pr√©paration des donn√©es</strong><br>
            Nettoyage, traitement des valeurs manquantes, encodage des variables cat√©gorielles, normalisation
          </div>
          <div class="process-step">
            <strong style="color: #a78bfa;">√âtape 2 : Baseline lin√©aire</strong><br>
            Construction d'un mod√®le de r√©gression lin√©aire simple pour √©tablir une r√©f√©rence de performance
          </div>
          <div class="process-step">
            <strong style="color: #a78bfa;">√âtape 3 : Impl√©mentation from scratch</strong><br>
            D√©veloppement de la descente de gradient pour comprendre les fondements math√©matiques
          </div>
          <div class="process-step">
            <strong style="color: #a78bfa;">√âtape 4 : S√©lection du degr√© polynomial optimal</strong><br>
            Utilisation du BIC pour √©viter le surapprentissage
          </div>
          <div class="process-step">
            <strong style="color: #a78bfa;">√âtape 5 : R√©gularisation Ridge</strong><br>
            Application de la r√©gularisation pour stabiliser le mod√®le final
          </div>
        </div>
      </div>

      <div class="insight-box">
        <strong>üí° Pourquoi la r√©gression est-elle cruciale pour le business ?</strong><br><br>
        Pr√©dire avec pr√©cision les ventes permet de :<br>
        ‚Ä¢ <strong>Optimiser les stocks</strong> en anticipant la demande<br>
        ‚Ä¢ <strong>Ajuster les prix</strong> et les remises de mani√®re strat√©gique<br>
        ‚Ä¢ <strong>Identifier les commandes √† forte valeur</strong> pour ciblage marketing<br>
        ‚Ä¢ <strong>Planifier les ressources logistiques</strong> (shipping, warehousing)
      </div>
    </section>

    <!-- Model 1: Linear Regression (Baseline) -->
    <section class="section">
      <h2><span class="step-number">1</span> R√©gression Lin√©aire ‚Äî Mod√®le de Base</h2>

      <h3>üìê Fondement Math√©matique</h3>
      <p>
        La r√©gression lin√©aire cherche √† mod√©liser la relation entre les features <code>X</code> et la cible
        <code>y</code>
        par une combinaison lin√©aire :
      </p>

      <div class="formula">
        ≈∑ = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + Œ≤‚ÇÇx‚ÇÇ + ... + Œ≤‚Çôx‚Çô
      </div>

      <p>
        L'objectif est de minimiser la <strong>fonction de co√ªt MSE (Mean Squared Error)</strong> :
      </p>

      <div class="formula">
        MSE = (1/n) Œ£(y·µ¢ - ≈∑·µ¢)¬≤
      </div>

      <h3>üîß Impl√©mentation et R√©sultats</h3>

      <div class="results-grid">
        <div class="metric-card">
          <h4>R¬≤ Test</h4>
          <div class="value">0.673</div>
        </div>
        <div class="metric-card">
          <h4>MAE Test</h4>
          <div class="value">$139.2</div>
        </div>
        <div class="metric-card">
          <h4>RMSE Test</h4>
          <div class="value">$223.6</div>
        </div>
        <div class="metric-card">
          <h4>R¬≤ Train</h4>
          <div class="value">0.737</div>
        </div>
      </div>

      <div class="image-wrapper">
        <img src="images/linear_4plots.png" alt="Diagnostic plots - R√©gression lin√©aire" />
        <p class="image-caption">Figure 1 : Diagnostics de la r√©gression lin√©aire (r√©sidus, QQ-plot, leverage)</p>
      </div>

      <div class="methodology-box">
        <h4 style="color: #667eea; margin-top: 0;">üìä Interpr√©tation des Diagnostics</h4>
        <p><strong>1. Residuals vs Fitted :</strong> On observe une <em>courbure syst√©matique</em> dans les r√©sidus,
          ce qui indique que le mod√®le lin√©aire ne capture pas toutes les relations. Cette courbure sugg√®re la pr√©sence
          de <strong>non-lin√©arit√©s</strong> dans les donn√©es.</p>

        <p><strong>2. QQ-Plot :</strong> Les extr√©mit√©s s'√©loignent de la diagonale, r√©v√©lant des <em>queues
            lourdes</em>
          (outliers). Le mod√®le sous-estime les valeurs extr√™mes.</p>

        <p><strong>3. Scale-Location :</strong> L'h√©t√©rosc√©dasticit√© est pr√©sente ‚Äî la variance des r√©sidus n'est pas
          constante.</p>

        <p><strong>4. Leverage :</strong> Quelques points √† fort leverage (influence), mais pas de points hors de la
          distance de Cook critique.</p>
      </div>

      <div class="insight-box">
        <strong>‚úÖ Points forts :</strong> Mod√®le simple, interpr√©table, rapide √† entra√Æner<br>
        <strong>‚ö†Ô∏è Limites :</strong> R¬≤ = 67.3% signifie que <strong>32.7% de la variance</strong> n'est pas expliqu√©e.
        La MAE de $139 reste √©lev√©e pour des d√©cisions business pr√©cises. Les r√©sidus montrent clairement des patterns
        non captur√©s ‚Üí n√©cessit√© d'enrichir le mod√®le.
      </div>
    </section>

    <!-- Model 2: Gradient Descent from Scratch -->
    <section class="section">
      <h2><span class="step-number">2</span> Descente de Gradient ‚Äî Impl√©mentation from Scratch</h2>

      <h3>üßÆ Comprendre l'Optimisation par Gradient Descent</h3>
      <p>
        Au lieu d'utiliser la solution analytique (√©quations normales), nous impl√©mentons l'algorithme de
        <strong>descente de gradient</strong> pour comprendre comment les mod√®les apprennent it√©rativement.
      </p>

      <div class="formula">
        Œ∏ := Œ∏ - Œ± √ó ‚àáJ(Œ∏)
      </div>

      <p style="text-align: center; color: #9ca3af; margin-top: 10px;">
        o√π <code>Œ±</code> est le learning rate et <code>‚àáJ(Œ∏)</code> est le gradient de la fonction de co√ªt
      </p>

      <div class="methodology-box">
        <h4 style="color: #667eea; margin-top: 0;">‚öôÔ∏è Processus d'Optimisation</h4>
        <ol style="line-height: 2;">
          <li><strong>Initialisation al√©atoire</strong> des poids Œ∏</li>
          <li><strong>Forward pass :</strong> Calcul des pr√©dictions ≈∑ = XŒ∏</li>
          <li><strong>Calcul de l'erreur :</strong> MSE = (1/n)||y - ≈∑||¬≤</li>
          <li><strong>Backward pass :</strong> Calcul du gradient ‚àáŒ∏ = (2/n)X·µÄ(≈∑ - y)</li>
          <li><strong>Mise √† jour :</strong> Œ∏ = Œ∏ - Œ±√ó‚àáŒ∏</li>
          <li><strong>R√©p√©tition</strong> jusqu'√† convergence</li>
        </ol>
      </div>

      <div class="image-wrapper">
        <img src="images/gd_convergence.png" alt="Convergence de la descente de gradient" />
        <p class="image-caption">Figure 2 : √âvolution de la MSE pour diff√©rents learning rates</p>
      </div>

      <h3>üèÜ R√©sultats et Le√ßons Apprises</h3>

      <div class="results-grid">
        <div class="metric-card best">
          <h4>Learning Rate Optimal</h4>
          <div class="value">0.1</div>
        </div>
        <div class="metric-card">
          <h4>R¬≤ Test</h4>
          <div class="value">0.680</div>
        </div>
        <div class="metric-card">
          <h4>MAE Test</h4>
          <div class="value">$119.8</div>
        </div>
        <div class="metric-card">
          <h4>Convergence</h4>
          <div class="value" style="font-size: 2rem;">‚úì</div>
        </div>
      </div>

      <div class="insight-box">
        <strong>üéì Enseignements Cl√©s :</strong><br><br>
        ‚Ä¢ <strong>Le choix du learning rate est critique :</strong> trop petit (0.001) ‚Üí convergence lente ;
        trop grand (0.3) ‚Üí divergence<br>
        ‚Ä¢ <strong>Le taux optimal (0.1)</strong> permet une convergence rapide en ~100 it√©rations<br>
        ‚Ä¢ <strong>La normalisation des features est indispensable</strong> ‚Äî sans StandardScaler,
        le gradient descent √©choue car les features ont des √©chelles diff√©rentes<br>
        ‚Ä¢ Notre impl√©mentation <strong>r√©plique presque exactement</strong> les performances de scikit-learn
        (R¬≤ ‚âà 0.68), validant notre compr√©hension math√©matique
      </div>

      <div class="success-box">
        <strong>‚ú® Impact p√©dagogique :</strong> Cette impl√©mentation d√©montre une ma√Ætrise des fondamentaux
        du Machine Learning au-del√† de l'utilisation de biblioth√®ques. Nous comprenons maintenant
        <em>comment</em> et <em>pourquoi</em> les mod√®les apprennent.
      </div>
    </section>

    <!-- Model 3: Visual 3D -->
    <section class="section">
      <h2><span class="step-number">3</span> Visualisation 3D ‚Äî Pourquoi le Mod√®le Lin√©aire Est Insuffisant</h2>

      <p>
        Pour mieux comprendre les limites du mod√®le lin√©aire, nous visualisons la relation entre
        <strong>Quantity</strong>, <strong>Discount</strong> et <strong>Sales</strong> dans un espace 3D.
      </p>

      <div class="image-wrapper">
        <img src="images/3d_plane.png" alt="Plan de r√©gression 3D" />
        <p class="image-caption">Figure 3 : Plan de r√©gression lin√©aire dans l'espace (Quantity, Discount, Sales)</p>
      </div>

      <div class="formula">
        Sales ‚âà 28 + 71√óQuantity - 184√óDiscount
      </div>

      <div class="insight-box">
        <strong>üìà Interpr√©tation Visuelle :</strong><br><br>
        ‚Ä¢ <strong>Quantity</strong> a un impact <em>positif</em> : plus on commande, plus les ventes augmentent (+$71
        par unit√©)<br>
        ‚Ä¢ <strong>Discount</strong> a un impact <em>n√©gatif</em> : les remises r√©duisent les ventes de montant (-$184
        par point de discount)<br>
        ‚Ä¢ <strong>Probl√®me :</strong> De nombreux points sont <em>loin du plan</em>, notamment pour des discounts √©lev√©s
      </div>

      <div class="warning-box">
        <strong>‚ö†Ô∏è Limite Fondamentale du Mod√®le Lin√©aire :</strong><br><br>
        Le plan 2D ne peut capturer la <strong>relation non-lin√©aire entre Discount et Sales</strong>.
        En r√©alit√©, l'effet du discount n'est pas constant ‚Äî il peut avoir un impact diff√©rent selon
        d'autres facteurs (cat√©gorie produit, segment client, etc.). C'est pourquoi nous avons besoin
        de <strong>features polynomiales</strong> pour capturer ces interactions.
      </div>
    </section>

    <!-- Model 4: Polynomial Degree Selection -->
    <section class="section">
      <h2><span class="step-number">4</span> S√©lection du Degr√© Polynomial Optimal (BIC)</h2>

      <h3>üî¨ Le Dilemme Biais-Variance</h3>
      <p>
        Augmenter le degr√© polynomial permet de capturer des relations complexes, mais risque le
        <strong>surapprentissage (overfitting)</strong>. Comment choisir le bon compromis ?
      </p>

      <div class="methodology-box">
        <h4 style="color: #667eea; margin-top: 0;">üìâ Crit√®re d'Information Bay√©sien (BIC)</h4>
        <p>Le BIC p√©nalise la complexit√© du mod√®le pour √©viter l'overfitting :</p>

        <div class="formula">
          BIC = n√óln(MSE) + k√óln(n)
        </div>

        <p style="text-align: center; color: #9ca3af; margin-top: 10px;">
          o√π <code>n</code> = nombre d'observations, <code>k</code> = nombre de param√®tres
        </p>

        <p style="margin-top: 20px;">
          <strong>Principe :</strong> Plus le BIC est <em>faible</em>, meilleur est le mod√®le. Le terme
          <code>k√óln(n)</code>
          p√©nalise les mod√®les complexes avec beaucoup de param√®tres.
        </p>
      </div>

      <div class="image-grid">
        <div class="image-wrapper">
          <img src="images/bic_curve.png" alt="BIC vs Degr√© polynomial" />
          <p class="image-caption">Figure 4 : √âvolution du BIC selon le degr√©</p>
        </div>
        <div class="image-wrapper">
          <img src="images/poly_degree8_fit.png" alt="Fit polynomial degr√© 8" />
          <p class="image-caption">Figure 5 : Ajustement excessif du degr√© 8</p>
        </div>
      </div>

      <h3>üìä R√©sultats et Paradoxe</h3>

      <table>
        <thead>
          <tr>
            <th>Degr√©</th>
            <th># Param√®tres</th>
            <th>BIC (Train)</th>
            <th>R¬≤ Test</th>
            <th>Verdict</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>1 (lin√©aire)</td>
            <td>5</td>
            <td>634 215</td>
            <td>0.673</td>
            <td>Baseline</td>
          </tr>
          <tr style="background: rgba(52, 211, 153, 0.15);">
            <td><strong>2</strong></td>
            <td><strong>15</strong></td>
            <td><strong>633 180</strong></td>
            <td><strong>0.784</strong></td>
            <td><strong>‚úÖ OPTIMAL</strong></td>
          </tr>
          <tr>
            <td>3</td>
            <td>35</td>
            <td>632 988</td>
            <td>0.801</td>
            <td>D√©but overfit</td>
          </tr>
          <tr style="background: rgba(251, 146, 60, 0.15);">
            <td>8</td>
            <td>495</td>
            <td>632 941 (min)</td>
            <td>‚àí67 495 ‚ùå</td>
            <td>Overfit catastrophique</td>
          </tr>
        </tbody>
      </table>

      <div class="warning-box">
        <strong>‚ö†Ô∏è Le Pi√®ge du Degr√© 8 :</strong><br><br>
        Bien que le degr√© 8 ait le <em>BIC le plus bas sur le training set</em>, il produit un
        <strong>R¬≤ n√©gatif catastrophique sur le test set (‚àí67 495)</strong>. Cela signifie que le mod√®le
        est <strong>pire qu'une simple moyenne</strong> !<br><br>

        <strong>Explication :</strong> Avec 495 param√®tres, le mod√®le m√©morise parfaitement les donn√©es
        d'entra√Ænement (y compris le bruit), mais <em>explose</em> sur de nouvelles donn√©es. Les courbes
        polynomiales cr√©ent des oscillations extr√™mes hors de la plage d'entra√Ænement.
      </div>

      <div class="success-box">
        <strong>‚úÖ Pourquoi le Degr√© 2 est Optimal :</strong><br><br>
        ‚Ä¢ <strong>BIC comp√©titif</strong> (633 180) ‚Äî l√©g√®rement sup√©rieur au degr√© 8, mais beaucoup plus stable<br>
        ‚Ä¢ <strong>R¬≤ Test = 0.784</strong> ‚Äî excellente g√©n√©ralisation (am√©lioration de +16% vs lin√©aire)<br>
        ‚Ä¢ <strong>15 param√®tres seulement</strong> ‚Äî mod√®le parcimonieux et interpr√©table<br>
        ‚Ä¢ Capture les <strong>interactions quadratiques essentielles</strong> (ex: Discount¬≤, Quantity√óDiscount)
        sans cr√©er d'instabilit√©s
      </div>
    </section>

    <!-- Model 5: Final Polynomial + Ridge -->
    <section class="section">
      <h2><span class="step-number">5</span> Mod√®le Final ‚Äî Polynomial Degr√© 2 + R√©gularisation Ridge üèÜ</h2>

      <h3>üõ°Ô∏è Ajout de la R√©gularisation Ridge</h3>
      <p>
        Pour stabiliser davantage le mod√®le et √©viter tout risque d'overfitting, nous ajoutons une
        <strong>p√©nalit√© L2 (Ridge)</strong> qui contraint les poids √† rester petits.
      </p>

      <div class="formula">
        J(Œ∏) = MSE + Œª √ó ||Œ∏||¬≤
      </div>

      <p style="text-align: center; color: #9ca3af; margin-top: 10px;">
        o√π <code>Œª</code> (alpha) contr√¥le l'intensit√© de la r√©gularisation
      </p>

      <div class="methodology-box">
        <h4 style="color: #667eea; margin-top: 0;">üîß Pipeline Final</h4>
        <ol style="line-height: 2;">
          <li><strong>StandardScaler</strong> : Normalisation des 4 features num√©riques (Quantity, Discount, Profit,
            Shipping Cost)</li>
          <li><strong>PolynomialFeatures(degree=2)</strong> : G√©n√©ration de 15 features polynomiales (interactions +
            carr√©s)</li>
          <li><strong>Ridge(alpha=1.0)</strong> : R√©gression avec p√©nalit√© L2</li>
        </ol>

        <p style="margin-top: 20px;">
          Ce pipeline est appliqu√© <strong>uniquement sur les 4 colonnes num√©riques</strong> pour √©viter
          une explosion combinatoire (appliquer degree=2 sur 16 features cr√©erait des milliers de colonnes).
        </p>
      </div>

      <h3>üéØ Performances Finales</h3>

      <div class="results-grid">
        <div class="metric-card best">
          <h4>R¬≤ Test</h4>
          <div class="value">0.784</div>
          <small style="color: #34d399;">+16.5% vs lin√©aire</small>
        </div>
        <div class="metric-card best">
          <h4>MAE Test</h4>
          <div class="value">$110.3</div>
          <small style="color: #34d399;">-$29 vs lin√©aire</small>
        </div>
        <div class="metric-card best">
          <h4>RMSE Test</h4>
          <div class="value">$181.5</div>
          <small style="color: #34d399;">-$42 vs lin√©aire</small>
        </div>
        <div class="metric-card best">
          <h4>R¬≤ Train</h4>
          <div class="value">0.801</div>
          <small style="color: #9ca3af;">L√©ger gap ‚Üí bon √©quilibre</small>
        </div>
      </div>

      <div class="image-grid">
        <div class="image-wrapper">
          <img src="images/degree_vs_performance.png" alt="Performance par degr√©" />
          <p class="image-caption">Figure 6 : R¬≤ Test selon le degr√© polynomial</p>
        </div>
        <div class="image-wrapper">
          <img src="images/sales_vs_discount.png" alt="Courbe Sales vs Discount" />
          <p class="image-caption">Figure 7 : Capture de la non-lin√©arit√© Discount/Sales</p>
        </div>
      </div>

      <div class="image-grid">
        <div class="image-wrapper">
          <img src="images/residuals_degree2.png" alt="R√©sidus degr√© 2" />
          <p class="image-caption">Figure 8 : R√©sidus du mod√®le polynomial degr√© 2</p>
        </div>
        <div class="image-wrapper">
          <img src="images/residual_distribution.png" alt="Distribution des r√©sidus" />
          <p class="image-caption">Figure 9 : Distribution des r√©sidus (quasi-normale)</p>
        </div>
      </div>

      <div class="success-box">
        <h4 style="color: #34d399; margin-top: 0;">üèÜ Mod√®le Champion ‚Äî Justification du Choix</h4>

        <p><strong>1. Performance robuste :</strong></p>
        <ul style="line-height: 1.8;">
          <li>R¬≤ = 0.784 signifie que notre mod√®le explique <strong>78.4% de la variance des ventes</strong></li>
          <li>MAE = $110 ‚Üí en moyenne, nos pr√©dictions s'√©cartent de ¬±$110 des ventes r√©elles</li>
          <li>Le gap Train/Test est minime (0.801 vs 0.784) ‚Üí <strong>excellente g√©n√©ralisation</strong></li>
        </ul>

        <p style="margin-top: 20px;"><strong>2. Interpr√©tabilit√© business :</strong></p>
        <ul style="line-height: 1.8;">
          <li>Le mod√®le capture l'<strong>effet quadratique du discount</strong> : petites remises ‚Üí bon impact ;
            remises excessives ‚Üí effondrement des ventes totales</li>
          <li>Les <strong>interactions Quantity√óDiscount</strong> r√©v√®lent que l'effet du discount varie selon le volume
            command√©</li>
        </ul>

        <p style="margin-top: 20px;"><strong>3. Parcimonie et stabilit√© :</strong></p>
        <ul style="line-height: 1.8;">
          <li>Seulement <strong>15 features polynomiales</strong> ‚Üí mod√®le l√©ger, rapide en production</li>
          <li>Ridge √©vite l'explosion des coefficients et renforce la robustesse face √† de nouvelles donn√©es</li>
        </ul>
      </div>

      <div class="insight-box">
        <strong>üíº Implications Pratiques :</strong><br><br>
        Avec une pr√©cision de ¬±$110, ce mod√®le permet de :<br>
        ‚Ä¢ <strong>Pr√©dire les revenus</strong> d'une commande avant sa validation<br>
        ‚Ä¢ <strong>Optimiser les strat√©gies de pricing</strong> en simulant l'impact de diff√©rents niveaux de
        discount<br>
        ‚Ä¢ <strong>D√©tecter les anomalies</strong> : commandes dont le montant pr√©dit s'√©carte fortement de la r√©alit√©
        (possibles erreurs ou fraudes)<br>
        ‚Ä¢ <strong>Alimenter un mod√®le ensemble</strong> en combinaison avec Random Forest, XGBoost, etc. pour atteindre
        R¬≤ > 0.96
      </div>
    </section>

    <!-- Comparison & Conclusion -->
    <section class="section">
      <h2>üìä Comparaison R√©capitulative et Conclusion</h2>

      <table>
        <thead>
          <tr>
            <th>Mod√®le</th>
            <th>R¬≤ Test</th>
            <th>MAE Test</th>
            <th>Temps Train</th>
            <th>Complexit√©</th>
            <th>Verdict</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Lin√©aire (Baseline)</td>
            <td>0.673</td>
            <td>$139.2</td>
            <td>~0.1s</td>
            <td>Faible</td>
            <td>R√©f√©rence solide</td>
          </tr>
          <tr>
            <td>Gradient Descent (scratch)</td>
            <td>0.680</td>
            <td>$119.8</td>
            <td>~2s</td>
            <td>Moyenne</td>
            <td>‚úÖ Validation p√©dagogique</td>
          </tr>
          <tr style="background: rgba(52, 211, 153, 0.15);">
            <td><strong>Polynomial Deg 2 + Ridge</strong></td>
            <td><strong>0.784</strong></td>
            <td><strong>$110.3</strong></td>
            <td><strong>~0.3s</strong></td>
            <td><strong>Optimale</strong></td>
            <td><strong>üèÜ CHAMPION</strong></td>
          </tr>
          <tr style="background: rgba(251, 146, 60, 0.15);">
            <td>Polynomial Deg 8</td>
            <td>‚àí67 495 ‚ùå</td>
            <td>N/A</td>
            <td>~1.5s</td>
            <td>Excessive</td>
            <td>Overfit catastrophique</td>
          </tr>
        </tbody>
      </table>

      <div class="success-box">
        <h3 style="color: #34d399; margin-top: 0;">üéì Synth√®se des Apprentissages</h3>

        <p><strong>1. M√©thodologie rigoureuse :</strong> Nous avons suivi une d√©marche scientifique compl√®te,
          du baseline au mod√®le optimis√©, en validant chaque √©tape par des diagnostics et m√©triques.</p>

        <p><strong>2. Compr√©hension profonde :</strong> L'impl√©mentation from scratch de la descente de gradient
          d√©montre une ma√Ætrise des fondamentaux math√©matiques, au-del√† de l'usage de biblioth√®ques.</p>

        <p><strong>3. Gestion du compromis biais-variance :</strong> Le choix du degr√© 2 (valid√© par BIC et
          performances test) illustre notre capacit√© √† √©viter le surapprentissage tout en capturant les
          non-lin√©arit√©s essentielles.</p>

        <p><strong>4. R√©gularisation strat√©gique :</strong> L'ajout de Ridge stabilise le mod√®le sans perte
          de performance, pr√©parant le terrain pour des ensembles futurs.</p>

        <p><strong>5. Valeur business :</strong> Une MAE de $110 est acceptable pour des d√©cisions op√©rationnelles
          (pricing, inventory) et constitue une base solide pour un mod√®le ensemble produisant R¬≤ > 0.96.</p>
      </div>

      <div class="insight-box">
        <strong>üöÄ Prochaines √âtapes :</strong><br><br>
        ‚Ä¢ <strong>Int√©gration dans un mod√®le ensemble</strong> (Voting, Stacking) avec Random Forest, XGBoost,
        LightGBM<br>
        ‚Ä¢ <strong>Feature engineering avanc√©</strong> : agr√©gations temporelles, encodages cat√©goriels optimis√©s<br>
        ‚Ä¢ <strong>D√©ploiement en production</strong> via API Flask/FastAPI pour pr√©dictions en temps r√©el<br>
        ‚Ä¢ <strong>Monitoring continu</strong> des performances pour d√©tecter le data drift
      </div>
    </section>

  </div>

  <!-- Footer -->
  <footer
    style="background: #0a0e27; border-top: 1px solid rgba(139, 92, 246, 0.3); padding: 40px 0; text-align: center; margin-top: 80px;">
    <div class="container">
      <p style="color: #9ca3af; font-size: 0.95rem;">
        ¬© 2025 Global Superstore ‚Äî Analyse de R√©gression Approfondie<br>
        <span style="color: #667eea;">Machine Learning Portfolio Project</span>
      </p>
    </div>
  </footer>

</body>

</html>